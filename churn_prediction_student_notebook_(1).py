# -*- coding: utf-8 -*-
"""Churn Prediction_Student_Notebook (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Jgo_dJsc8c-m7wTLyXdCt9fbBhPx8pph

___

<p style="text-align: center;"><img src="https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV" class="img-fluid" alt="CLRSWY"></p>

___

# WELCOME!

Welcome to "***Employee Churn Analysis Project***". This is the second project of Capstone Project Series, which you will be able to build your own classification models for a variety of business settings. 

Also you will learn what is Employee Churn?, How it is different from customer churn, Exploratory data analysis and visualization of employee churn dataset using ***matplotlib*** and ***seaborn***, model building and evaluation using python ***scikit-learn*** package. 

You will be able to implement classification techniques in Python. Using Scikit-Learn allowing you to successfully make predictions with the Random Forest, Gradient Descent Boosting , KNN algorithms.

At the end of the project, you will have the opportunity to deploy your model using *Streamlit*.

Before diving into the project, please take a look at the determines and project structure.

- NOTE: This project assumes that you already know the basics of coding in Python and are familiar with model deployement as well as the theory behind K-Means, Gradient Boosting , KNN, Random Forest, and Confusion Matrices. You can try more models and methods beside these to improve your model metrics.

# #Determines
In this project you have HR data of a company. A study is requested from you to predict which employee will churn by using this data.

The HR dataset has 14,999 samples. In the given dataset, you have two types of employee one who stayed and another who left the company.

You can describe 10 attributes in detail as:
- ***satisfaction_level:*** It is employee satisfaction point, which ranges from 0-1.
- ***last_evaluation:*** It is evaluated performance by the employer, which also ranges from 0-1.
- ***number_projects:*** How many of projects assigned to an employee?
- ***average_monthly_hours:*** How many hours in averega an employee worked in a month?
- **time_spent_company:** time_spent_company means employee experience. The number of years spent by an employee in the company.
- ***work_accident:*** Whether an employee has had a work accident or not.
- ***promotion_last_5years:*** Whether an employee has had a promotion in the last 5 years or not.
- ***Departments:*** Employee's working department/division.
- ***Salary:*** Salary level of the employee such as low, medium and high.
- ***left:*** Whether the employee has left the company or not.

First of all, to observe the structure of the data, outliers, missing values and features that affect the target variable, you must use exploratory data analysis and data visualization techniques. 

Then, you must perform data pre-processing operations such as ***Scaling*** and ***Label Encoding*** to increase the accuracy score of Gradient Descent Based or Distance-Based algorithms. you are asked to perform ***Cluster Analysis*** based on the information you obtain during exploratory data analysis and data visualization processes. 

The purpose of clustering analysis is to cluster data with similar characteristics. You are asked to use the ***K-means*** algorithm to make cluster analysis. However, you must provide the K-means algorithm with information about the number of clusters it will make predictions. Also, the data you apply to the K-means algorithm must be scaled. In order to find the optimal number of clusters, you are asked to use the ***Elbow method***. Briefly, try to predict the set to which individuals are related by using K-means and evaluate the estimation results.

Once the data is ready to be applied to the model, you must ***split the data into train and test***. Then build a model to predict whether employees will churn or not. Train your models with your train set, test the success of your model with your test set. 

Try to make your predictions by using the algorithms ***Gradient Boosting Classifier***, ***K Neighbors Classifier***, ***Random Forest Classifier***. You can use the related modules of the ***scikit-learn*** library. You can use scikit-learn ***Confusion Metrics*** module for accuracy calculation. You can use the ***Yellowbrick*** module for model selection and visualization.

In the final step, you will deploy your model using Streamlit tool.

# #Tasks

#### 1. Exploratory Data Analysis
- Importing Modules
- Loading Dataset
- Data Insigts

#### 2. Data Visualization
- Employees Left
- Determine Number of Projects
- Determine Time Spent in Company
- Subplots of Features

#### 3. Data Pre-Processing
- Scaling
- Label Encoding

#### 4. Cluster Analysis
- Find the optimal number of clusters (k) using the elbow method for for K-means.
- Determine the clusters by using K-Means then Evaluate predicted results.

#### 5. Model Building
- Split Data as Train and Test set
- Built Gradient Boosting Classifier, Evaluate Model Performance and Predict Test Data
- Built K Neighbors Classifier and Evaluate Model Performance and Predict Test Data
- Built Random Forest Classifier and Evaluate Model Performance and Predict Test Data

#### 6. Model Deployement

- Save and Export the Model as .pkl
- Save and Export Variables as .pkl

## 1. Exploratory Data Analysis

Exploratory Data Analysis is an initial process of analysis, in which you can summarize characteristics of data such as pattern, trends, outliers, and hypothesis testing using descriptive statistics and visualization.

### Importing Modules
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.neural_network import MLPClassifier

import warnings
warnings.filterwarnings('ignore')
pd.set_option('display.float_format', lambda x: '%.3f' % x)

"""### Loading Dataset

Let's first load the required HR dataset using pandas's "read_csv" function.
"""

df = pd.read_csv("HR_Dataset.csv")
df1=df.copy()
df1.head()

df1.info()

df1.describe()

len(df1[df1.duplicated()])

df1.drop_duplicates(inplace=True)
df1.reset_index(inplace=True, drop=True)
df1

"""### Data Insights

In the given dataset, you have two types of employee one who stayed and another who left the company. So, you can divide data into two groups and compare their characteristics. Here, you can find the average of both the groups using groupby() and mean() function.
"""

df1.groupby('left').mean()

"""## 2. Data Visualization

You can search for answers to the following questions using data visualization methods. Based on these responses, you can develop comments about the factors that cause churn.
- How does the promotion status affect employee churn?
- How does years of experience affect employee churn?
- How does workload affect employee churn?
- How does the salary level affect employee churn?

### Employees Left

Let's check how many employees were left?
Here, you can plot a bar graph using Matplotlib. The bar graph is suitable for showing discrete variable counts.
"""

plt.figure(figsize = (8, 6))
ax=sns.countplot(df1.left, palette = "crest")
for p in ax.patches:
        ax.annotate('{}'.format(p.get_height()), (p.get_x()+0.33, p.get_height()+50))
plt.title("Employee Churn Percentages", fontsize=15);

plt.figure(figsize = (10, 8))
_, _, autotexts = plt.pie(df1['left'].value_counts(ascending=False),labels=['0', '1'], autopct='%1.1f%%', explode=[0.025,0.025],
        wedgeprops = {"edgecolor" : "black", 'linewidth': 2, 'antialiased': True} , colors = ['#5a948a', '#2b667c']);
plt.title("Employee Churn Percentages", fontsize=15);
for ins in autotexts:
    ins.set_color('white');

"""### Number of Projects

Similarly, you can also plot a bar graph to count the number of employees deployed on how many projects?
"""

proj_df=pd.DataFrame(df1.groupby(['number_project','left'])['number_project'].sum())
proj_df=proj_df.reset_index(1)
proj_df

plt.figure(figsize = (12, 6))
ax=sns.barplot(x=proj_df.index, y=proj_df['number_project'], hue=proj_df.left, palette = "crest")
plt.title("Effects of Workload (Number of Projects) on Employee Churn", fontsize=15);
for container in ax.containers:
    ax.bar_label(container);

fig, ax=plt.subplots(figsize=(12,6))
sns.histplot(x = 'average_montly_hours' ,hue ='left' ,palette = "crest" , data= df1);
for container in ax.containers:
    ax.bar_label(container);
plt.title("Effects of Workload (Monthly Hours) on Employee Churn", fontsize=15);

"""Working on 6 and 7 project are too much workload for employees.

### Time Spent in Company

Similarly, you can also plot a bar graph to count the number of employees have based on how much experience?
"""

df1.groupby(['left','time_spend_company'])['time_spend_company'].count()

fig, ax=plt.subplots(figsize=(12,6))
sns.countplot(x = 'time_spend_company' ,hue ='left' ,palette = "crest" , data= df1);
plt.title("Effects of Time Spent in the Company on Employee Churn", fontsize=15);
for container in ax.containers:
    ax.bar_label(container);

fig, ax=plt.subplots(figsize=(12,6))
sns.countplot(x = 'promotion_last_5years' ,hue ='left' ,palette = "crest" , data= df1);
total = float(len(df1))
    
for p in ax.patches:
    percentage = '{:.1f}%'.format(100 * p.get_height()/total)
    x = p.get_x() + p.get_width()
    y = p.get_height()
    ax.annotate(percentage, (x-0.25, y+100))

plt.title("The Promotion Status Affecting Employee Churn", fontsize=15);

"""Approximately 74 percent of employees stayed and not promoted.

Approximately 24 percent of employees left and not promoted.

Approximately 2 percent of employees stayed and promoted.

Approximately 0.1 percent of employees left and promoted
"""

fig, ax=plt.subplots(figsize=(12,6))
sns.countplot(x = df1[df1.promotion_last_5years==1].promotion_last_5years ,hue ='left' ,palette = "crest" , data= df1);
total = float(len(df1[df1.promotion_last_5years==1]))
    
for p in ax.patches:
    percentage = '{:.1f}%'.format(100 * p.get_height()/total)
    x = p.get_x() + p.get_width()
    y = p.get_height()
    ax.annotate(percentage, (x-0.25, y+4))

plt.title("Employees Who Promoted Status Affecting Employee Churn", fontsize=15);

"""Approximately 94 percent of employees who promoted are stayed"""

df1.groupby(['left','salary'])['salary'].count()

fig, ax=plt.subplots(figsize=(10,6))
sns.countplot(x = 'salary' ,hue ='left' ,palette = "crest" , data= df1);
for container in ax.containers:
    ax.bar_label(container);
plt.title("Effects of Salary Status in the Company on Employee Churn", fontsize=15);

df1.groupby(['left','Work_accident'])['Work_accident'].count()

fig, ax=plt.subplots(figsize=(10,6))
sns.countplot(x = 'Work_accident' ,hue ='left' ,palette = "crest" , data= df1);
for container in ax.containers:
    ax.bar_label(container);
    plt.title("Effects of Work Accident on Employee Churn", fontsize=15);

fig, ax=plt.subplots(figsize=(12,6))
sns.countplot(x = 'Departments ' ,hue ='left' ,palette = "crest" , data= df1);
for container in ax.containers:
    ax.bar_label(container);
plt.title("Effects of Departments on Employee Churn", fontsize=15);

fig, ax=plt.subplots(figsize=(12,6))
sns.histplot(x = 'satisfaction_level' ,hue ='left' ,palette = "crest" , data= df1);
for container in ax.containers:
    ax.bar_label(container);
plt.title("Effects of Satisfaction Level on Employee Churn", fontsize=15);

fig, ax=plt.subplots(figsize=(12,6))
sns.histplot(x = 'last_evaluation' ,hue ='left' ,palette = "crest" , data= df1);
for container in ax.containers:
    ax.bar_label(container);
plt.title("Effects of Last Evaluation on Employee Churn", fontsize=15);

"""## 3. Data Pre-Processing

#### Ordinal Encoding

Lots of machine learning algorithms require numerical input data, so you need to represent categorical columns in a numerical column. In order to encode this data, you could map each value to a number. e.g. Salary column's value can be represented as low:0, medium:1, and high:2. This process is known as ordinal encoding, and sklearn conveniently will do this for you using [OrdinalEncoder](https://datascience.stackexchange.com/questions/39317/difference-between-ordinalencoder-and-labelencoder).
"""

plt.figure(figsize=(12,6))
sns.pairplot(df1,hue='left',palette='Dark2')

plt.figure(figsize=(10,8))
sns.heatmap(df1.select_dtypes("number").corr(),annot=True, cmap='crest')
plt.title("Correlation Matrix")

plt.show()

from sklearn.preprocessing import OrdinalEncoder
df_enc=df1.copy()
scale_mapper = {"Low":0, "Medium":1, "High":2}
df_enc["salary"] = df_enc["salary"].replace(scale_mapper)

enc = OrdinalEncoder()
df_enc[["salary"]] = enc.fit_transform(df_enc[["salary"]])

df_enc

from sklearn.preprocessing import OneHotEncoder
categorical_transformer = OneHotEncoder(handle_unknown="ignore")
cat=pd.DataFrame(categorical_transformer.fit_transform(df_enc[['Departments ']]).toarray())
df_enc=df_enc.join(cat)
df_enc.drop('Departments ', axis=1, inplace=True)
df_enc

"""#### Scaling

Some machine learning algorithms are sensitive to feature scaling while others are virtually invariant to it. Machine learning algorithms like linear regression, logistic regression, neural network, etc. that use gradient descent as an optimization technique require data to be scaled. Also distance algorithms like KNN, K-means, and SVM are most affected by the range of features. This is because behind the scenes they are using distances between data points to determine their similarity.

Scaling Types:
- Normalization: Normalization is a scaling technique in which values are shifted and rescaled so that they end up ranging between 0 and 1. It is also known as Min-Max scaling.

- Standardization: Standardization is another scaling technique where the values are centered around the mean with a unit standard deviation. This means that the mean of the attribute becomes zero and the resultant distribution has a unit standard deviation.

    
"""

df_enc.describe()

X = df_enc.drop(columns = ['left'])
y = df_enc['left']

from sklearn.preprocessing import scale, MinMaxScaler
scaler = MinMaxScaler() #Because it is not gaussian
scaler.fit(X)

X_scaled = scaler.transform(X)
X_scaled

"""## 4. Cluster Analysis

- Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) to each other than to those in other groups (clusters). It is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including pattern recognition, image analysis, information retrieval, bioinformatics, data compression, computer graphics and machine learning.

    [Cluster Analysis](https://en.wikipedia.org/wiki/Cluster_analysis)

    [Cluster Analysis2](https://realpython.com/k-means-clustering-python/)

#### The Elbow Method

- "Elbow Method" can be used to find the optimum number of clusters in cluster analysis. The elbow method is used to determine the optimal number of clusters in k-means clustering. The elbow method plots the value of the cost function produced by different values of k. If k increases, average distortion will decrease, each cluster will have fewer constituent instances, and the instances will be closer to their respective centroids. However, the improvements in average distortion will decline as k increases. The value of k at which improvement in distortion declines the most is called the elbow, at which we should stop dividing the data into further clusters.

    [The Elbow Method](https://en.wikipedia.org/wiki/Elbow_method_(clustering)

    [The Elbow Method2](https://medium.com/@mudgalvivek2911/machine-learning-clustering-elbow-method-4e8c2b404a5d)

    [KMeans](https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1)

Let's find out the groups of employees who left. You can observe that the most important factor for any employee to stay or leave is satisfaction and performance in the company. So let's bunch them in the group of people using cluster analysis.
"""

# pip install pyclustertend

from pyclustertend import hopkins

hopkins(X_scaled, X_scaled.shape[0])

from sklearn.cluster import KMeans

ks = range(1,10)
inertias=[]
for k in ks :
    # Create a KMeans clusters
    kc = KMeans(n_clusters=k,random_state=1)
    kc.fit(X_scaled)
    inertias.append(kc.inertia_)

# Plot ks vs inertias
f, ax = plt.subplots(figsize=(8, 6))
plt.plot(ks, inertias, '-o')
plt.xlabel('Number of clusters, k')
plt.ylabel('Inertia')
plt.xticks(ks)
plt.style.use('ggplot')
plt.title('What is the Best Number for KMeans ?')
plt.show()

from yellowbrick.cluster import KElbowVisualizer

kmeans = KMeans()
visu = KElbowVisualizer(kmeans, k = (1,10))
visu.fit(X_scaled)
visu.show();

from sklearn.metrics import silhouette_samples,silhouette_score

ssd =[]

K = range(2, 10)

for k in K:
    model = KMeans(n_clusters=k)
    model.fit(X_scaled)
    ssd.append(model.inertia_)
    print(f'Silhouette Score for {k} clusters: {silhouette_score(X_scaled, model.labels_)}')

from sklearn.cluster import KMeans

from yellowbrick.cluster import SilhouetteVisualizer

model_4 = KMeans(n_clusters=4, random_state=101)
visualizer = SilhouetteVisualizer(model_4)
visualizer.fit(X_scaled)    # Fit the data to the visualizer
visualizer.poof();

model_2 = KMeans(n_clusters=2, random_state=101)
visualizer = SilhouetteVisualizer(model_2)
visualizer.fit(X_scaled)    # Fit the data to the visualizer
visualizer.poof();

k_means_model = KMeans(n_clusters = 2, random_state = 101)
k_means_model.fit_predict(X_scaled)
labels = k_means_model.labels_
labels

df2=df1.copy()
df2['predicted_clusters'] = labels
df2.head()

pd.crosstab(df2['left'], df2['predicted_clusters'])

df2.groupby(['predicted_clusters']).mean()

df2.groupby(['predicted_clusters', 'left']).mean()

"""## 5. Model Building

### Split Data as Train and Test Set

Here, Dataset is broken into two parts, for example, in ratio of 70:30. It means 70% data will used for model training and 30% for model testing.
"""

from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import OrdinalEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import cross_validate,  cross_val_score
from sklearn.metrics import classification_report, confusion_matrix, f1_score, make_scorer, precision_score, recall_score
from sklearn.metrics import plot_roc_curve, roc_auc_score, roc_curve, f1_score, accuracy_score, recall_score

df_enc.head()

X = df_enc.drop('left', axis=1)
y = df_enc['left']

X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.3, random_state = 101)

scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

from sklearn.metrics import confusion_matrix,classification_report,plot_confusion_matrix

def eval_metric(model, X_train, y_train, X_test, y_test):
    y_train_pred = model.predict(X_train)
    y_pred = model.predict(X_test)
    
    print("Test_Set")
    print(confusion_matrix(y_test, y_pred))
    print(classification_report(y_test, y_pred))
    print()
    print("Train_Set")
    print(confusion_matrix(y_train, y_train_pred))
    print(classification_report(y_train, y_train_pred))

"""### #Gradient Boosting Classifier

#### Model Building
"""

GB_model = GradientBoostingClassifier(random_state = 101)
GB_model.fit(X_train, y_train)
y_pred = GB_model.predict(X_test)

"""#### Evaluating Model Performance"""

eval_metric(GB_model, X_train, y_train, X_test, y_test)

"""- Confusion Matrix : You can use scikit-learn metrics module for accuracy calculation. A Confusion matrix is an N x N matrix used for evaluating the performance of a classification model, where N is the number of target classes. The matrix compares the actual target values with those predicted by the machine learning model. This gives us a holistic view of how well our classification model is performing and what kinds of errors it is making.

    [Confusion Matrix](https://www.analyticsvidhya.com/blog/2020/04/confusion-matrix-machine-learning/)
"""

plot_confusion_matrix(GB_model, X_test, y_test, cmap="crest")

"""- Yellowbrick: Yellowbrick is a suite of visualization and diagnostic tools that will enable quicker model selection. It’s a Python package that combines scikit-learn and matplotlib. Some of the more popular visualization tools include model selection, feature visualization, classification and regression visualization

    [Yellowbrick](https://www.analyticsvidhya.com/blog/2018/05/yellowbrick-a-set-of-visualization-tools-to-accelerate-your-model-selection-process/)
"""

from yellowbrick.classifier import ClassPredictionError

visualizer = ClassPredictionError(GB_model)

# Fit the training data to the visualizer
visualizer.fit(X_train, y_train)

# Evaluate the model on the test data
visualizer.score(X_test, y_test)

# Draw visualization
visualizer.poof();

GB_feature_imp = pd.DataFrame(index=X.columns, data = GB_model.feature_importances_, columns = ['Feature Importance']).sort_values("Feature Importance", ascending = False)
GB_feature_imp

plt.figure(figsize = (12,6))
sns.barplot(data = GB_feature_imp.sort_values('Feature Importance', ascending = False), x = GB_feature_imp.sort_values('Feature Importance', ascending = False).index, y = 'Feature Importance')
plt.xticks(rotation = 75);

GB_cv_scores = cross_validate(GB_model, X_train, y_train, 
                              scoring = ['accuracy', 'precision','recall', 'f1'], cv = 10)
GB_cv_scores = pd.DataFrame(GB_cv_scores, index = range(1, 11))

GB_cv_scores.mean()[2:]

param_grid = {'n_estimators':[50, 100, 300],
             'max_features':[2, 3, 4, "none"],
             'max_depth':[3, 5, 7, 9],
             'min_samples_split':[2, 5, 8]}

from sklearn.model_selection import GridSearchCV
GB_grid_model = GridSearchCV(GB_model, param_grid, scoring = "recall", n_jobs = -1, verbose = 2).fit(X_train, y_train)

GB_grid_model.best_estimator_

eval_metric(GB_grid_model, X_train, y_train, X_test, y_test)

plot_confusion_matrix(GB_grid_model, X_test, y_test, cmap="crest")

visualizer = ClassPredictionError(GB_grid_model)
visualizer.fit(X_train, y_train)
visualizer.score(X_test, y_test)
visualizer.poof();

GB_tuned = GradientBoostingClassifier(max_features=4, n_estimators=300).fit(X_train, y_train)

y_pred = GB_tuned.predict(X_test)
y_train_pred = GB_tuned.predict(X_train)

GB_tuned_f1 = f1_score(y_test, y_pred)
GB_tuned_acc = accuracy_score(y_test, y_pred)
GB_tuned_recall = recall_score(y_test, y_pred)
GB_tuned_pre = precision_score(y_test, y_pred)

"""#### Prediction"""

GB_Pred = {"Actual": y_test, "GB_Pred":y_pred}
GB_Pred = pd.DataFrame.from_dict(GB_Pred)
GB_Pred.head(20)

"""### #KNeighbors Classifier

#### Model Building
"""

from sklearn.neighbors import KNeighborsClassifier

test_error_rates = []

for k in range(1,30):
    KNN_model = KNeighborsClassifier(n_neighbors=k)
    KNN_model.fit(X_train,y_train) 
   
    y_pred = KNN_model.predict(X_test)
        
    test_error = 1 - accuracy_score(y_test,y_pred)
    
    test_error_rates.append(test_error)
      
print(test_error_rates)

plt.figure(figsize=(15,8))
plt.plot(range(1,30), test_error_rates, color='blue', linestyle='--', marker='o',
         markerfacecolor='red', markersize=10)

plt.title('Error Rate vs. K Value')
plt.xlabel('K_values')
plt.ylabel('Error Rate')
plt.hlines(y=0.042523, xmin = 0, xmax = 30, colors= 'r', linestyles="--")
plt.hlines(y=0.044747, xmin = 0, xmax = 30, colors= 'r', linestyles="--")

KNN_model = KNeighborsClassifier(n_neighbors = 2)
KNN_model.fit(X_train,y_train)
eval_metric(KNN_model, X_train, y_train, X_test, y_test)

KNN_tuned_f1 = f1_score(y_test, y_pred)
KNN_tuned_acc = accuracy_score(y_test, y_pred)
KNN_tuned_recall = recall_score(y_test, y_pred)
KNN_tuned_pre = precision_score(y_test, y_pred)

KNN4_model = KNeighborsClassifier(n_neighbors = 4)
KNN4_model.fit(X_train,y_train)
eval_metric(KNN4_model, X_train, y_train, X_test, y_test)

KNN5_model = KNeighborsClassifier(n_neighbors = 5)
KNN5_model.fit(X_train,y_train)
eval_metric(KNN5_model, X_train, y_train, X_test, y_test)

"""#### Evaluating Model Performance"""

plot_confusion_matrix(KNN_model, X_test, y_test, cmap="crest")

visualizer = ClassPredictionError(KNN_model)
visualizer.fit(X_train, y_train)
visualizer.score(X_test, y_test)
visualizer.poof();

"""#### Prediction"""

KNN_Pred = {"Actual": y_test, "KNN_Pred":y_pred}
KNN_Pred = pd.DataFrame.from_dict(KNN_Pred)
KNN_Pred.head(20)

Model_Preds = GB_Pred.merge((KNN_Pred.drop("Actual", axis = 1)), left_index = True, right_index = True)
Model_Preds.head(20)

"""### #Random Forest Classifier

#### Model Building
"""

from sklearn.ensemble import RandomForestClassifier

RF_model = RandomForestClassifier(class_weight = "balanced", random_state = 101)
RF_model.fit(X_train, y_train)
y_pred = RF_model.predict(X_test)

"""#### Evaluating Model Performance"""

eval_metric(RF_model, X_train, y_train, X_test, y_test)

plot_confusion_matrix(RF_model, X_test, y_test, cmap="crest")

visualizer = ClassPredictionError(RF_model)
visualizer.fit(X_train, y_train)
visualizer.score(X_test, y_test)
visualizer.poof();

rf_feature_imp = pd.DataFrame(index = X.columns, data = RF_model.feature_importances_,
                              columns = ["Feature Importance"]).sort_values("Feature Importance", ascending = False)
rf_feature_imp

plt.figure(figsize = (12,6))
ax = sns.barplot(y=rf_feature_imp["Feature Importance"], x=rf_feature_imp.index)
plt.title("Feature Importance for Random Forest")
plt.xticks(rotation = 75);

RF_cv_scores = cross_validate(RF_model, X_train, y_train, scoring = ['accuracy', 'precision', 'recall', 'f1'], cv = 10)
RF_cv_scores = pd.DataFrame(RF_cv_scores, index = range(1, 11))

RF_cv_scores.mean()[2:]

param_grid = {'n_estimators':[50, 100, 300],
             'max_features':[3, 4, 5, 6, 7, "auto"],
             'max_depth':[3, 5, 7, 9],
             'min_samples_split':[2, 5, 8]}

from sklearn.model_selection import GridSearchCV
RF_grid_model = GridSearchCV(RF_model, param_grid, scoring = "recall", n_jobs = -1, verbose = 2).fit(X_train, y_train)

RF_grid_model.best_params_

eval_metric(RF_grid_model, X_train, y_train, X_test, y_test)

plot_confusion_matrix(RF_grid_model, X_test, y_test, cmap="crest")

visualizer = ClassPredictionError(RF_grid_model)
visualizer.fit(X_train, y_train)
visualizer.score(X_test, y_test)
visualizer.poof();

plot_roc_curve(RF_model, X_test, y_test);

from sklearn.metrics import make_scorer, precision_score, precision_recall_curve, plot_precision_recall_curve 
plot_precision_recall_curve(RF_model, X_test, y_test);

RF_tuned = RandomForestClassifier(class_weight = 'balanced',
                                  max_depth = 3,
                                  max_features = 6,
                                  n_estimators = 100,
                                  min_samples_split = 2,
                                  random_state = 101).fit(X_train, y_train)

y_pred = RF_tuned.predict(X_test)
y_train_pred = RF_tuned.predict(X_train)

RF_tuned_f1 = f1_score(y_test, y_pred)
RF_tuned_acc = accuracy_score(y_test, y_pred)
RF_tuned_recall = recall_score(y_test, y_pred)
RF_tuned_pre = precision_score(y_test, y_pred)

"""#### Prediction"""

RF_Pred = {"Actual": y_test, "RF_Pred":y_pred}
RF_Pred = pd.DataFrame.from_dict(RF_Pred)
RF_Pred.head(20)

Model_Preds = pd.merge(Model_Preds, (RF_Pred.drop("Actual", axis = 1)), left_index = True, right_index = True)
Model_Preds.head(20)

Model_Preds.sample(20)

compare = pd.DataFrame({"Model": ["GB_tuned", "KNN_tuned", "RF_tuned"],
                        
                        "F1_Score": [GB_tuned_f1, KNN_tuned_f1, RF_tuned_f1],
                                                 
                        "Accuracy_Score": [GB_tuned_acc, KNN_tuned_acc, RF_tuned_acc],
                        
                        "Recall_Score": [GB_tuned_recall, KNN_tuned_recall, RF_tuned_recall],
                       
                        "Precision_Score": [GB_tuned_pre, KNN_tuned_pre, RF_tuned_pre]})

compare = compare.sort_values(by="Recall_Score", ascending=True)
fig = px.bar(compare, x = "Recall_Score", y = "Model", title = "Recall_Score")
fig.show()

compare = compare.sort_values(by="F1_Score", ascending=True)
fig = px.bar(compare, x = "F1_Score", y = "Model", title = "F1_Score")
fig.show()

compare = compare.sort_values(by="Accuracy_Score", ascending=True)
fig = px.bar(compare, x = "Accuracy_Score", y = "Model", title = "Accuracy_Score")
fig.show()

"""## 6. Model Deployement

You cooked the food in the kitchen and moved on to the serving stage. The question is how do you showcase your work to others? Model Deployement helps you showcase your work to the world and make better decisions with it. But, deploying a model can get a little tricky at times. Before deploying the model, many things such as data storage, preprocessing, model building and monitoring need to be studied. Streamlit is a popular open source framework used by data scientists for model distribution.

Deployment of machine learning models, means making your models available to your other business systems. By deploying models, other systems can send data to them and get their predictions, which are in turn populated back into the company systems. Through machine learning model deployment, can begin to take full advantage of the model you built.

Data science is concerned with how to build machine learning models, which algorithm is more predictive, how to design features, and what variables to use to make the models more accurate. However, how these models are actually used is often neglected. And yet this is the most important step in the machine learning pipline. Only when a model is fully integrated with the business systems, real values ​​can be extract from its predictions.

After doing the following operations in this notebook, jump to new .py file and create your web app with Streamlit.
"""

import pickle
gradient_boosting_classifier = pickle.dump(GB_tuned, open('gradient_boosting_model', 'wb'))

"""### Save and Export the Model as .pkl"""



"""### Save and Export Variables as .pkl"""



"""___

<p style="text-align: center;"><img src="https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV" class="img-fluid" alt="CLRSWY"></p>

___
"""



X.describe()

from sklearn.neighbors import KNeighborsClassifier

scalers = [MinMaxScaler(), StandardScaler()]
models = [RandomForestClassifier(), GradientBoostingClassifier(), KNeighborsClassifier()]

import itertools

exp = list(itertools.product(models, scalers))

exp

from sklearn.model_selection import cross_val_score

from sklearn.model_selection import StratifiedKFold

model_names = []
scores_results = []

for mo, sc in exp:
    col = ColumnTransformer(
    transformers=[
        ('categorical', OneHotEncoder(handle_unknown='ignore'), ['Departments ']),
        ('scaler', sc, ['average_montly_hours', 'last_evaluation'] )
    ], remainder='passthrough')
    
    est = Pipeline (
    
    steps= [('preprocessor', col),('model', mo)])
    
    #est.fit(X_train, y_train)
    skf = StratifiedKFold(n_splits=10, shuffle=True)
    results = cross_val_score(est, X_train, y_train, cv=skf, scoring="recall")
    #preds = est.predict(X_test)
    #score = recall_score(y_test, preds)
    scores_results.append(results)
    print(results)
    name = str(mo)[:-2] + " " + str(sc)[:-2]
    model_names.append(name)
    
    print(f"Score for {mo} with {sc}: {results.mean()}")

model_names

scores_results

len(scores_results)+1

import cufflinks as cf
import plotly.offline

cf.go_offline()
cf.set_config_file(offline=False, world_readable=True)

pd.DataFrame(scores_results, index=model_names, columns=[a for a in range(1, len(results)+1)]).T.iplot(kind="box", boxpoints="all")



col = ColumnTransformer(
    transformers=[
        ('categorical', OneHotEncoder(handle_unknown='ignore'), ['Departments ']),
        ('scaler', MinMaxScaler(), ['average_montly_hours', 'last_evaluation'] )
    ], remainder='passthrough'


)

est = Pipeline (
    
    steps= [('preprocessor', col),('model', GradientBoostingClassifier())]

)

X = df2.drop('left', axis=1)
y = df2['left']

X['salary']=df1['salary']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y ,random_state=101)

X_train.head()

est.fit(X_train, y_train)

numeric_features = ["salary"]
numeric_transformer = OrdinalEncoder()


categorical_features = ["Departments "]
categorical_transformer = OneHotEncoder(handle_unknown="ignore")


preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_transformer, numeric_features),
        ("cat", categorical_transformer, categorical_features),
    ]
)

X

pd.DataFrame(col.fit_transform(X_train), columns=get_feature_names(col))

# Commented out IPython magic to ensure Python compatibility.
def get_feature_names(column_transformer):
    """Get feature names from all transformers.
    Returns
    -------
    feature_names : list of strings
        Names of the features produced by transform.
    """
    # Remove the internal helper function
    #check_is_fitted(column_transformer)
    
    # Turn loopkup into function for better handling with pipeline later
    def get_names(trans):
        # >> Original get_feature_names() method
        if trans == 'drop' or (
                hasattr(column, '__len__') and not len(column)):
            return []
        if trans == 'passthrough':
            if hasattr(column_transformer, '_df_columns'):
                if ((not isinstance(column, slice))
                        and all(isinstance(col, str) for col in column)):
                    return column
                else:
                    return column_transformer._df_columns[column]
            else:
                indices = np.arange(column_transformer._n_features)
                return ['x%d' % i for i in indices[column]]
        if not hasattr(trans, 'get_feature_names'):
        # >>> Change: Return input column names if no method avaiable
            # Turn error into a warning
            warnings.warn("Transformer %s (type %s) does not "
                                 "provide get_feature_names. "
                                 "Will return input column names if available"
#                                  % (str(name), type(trans).__name__))
            # For transformers without a get_features_names method, use the input
            # names to the column transformer
            if column is None:
                return []
            else:
                return [name + "__" + f for f in column]

        return [name + "__" + f for f in trans.get_feature_names()]
    
    ### Start of processing
    feature_names = []
    
    # Allow transformers to be pipelines. Pipeline steps are named differently, so preprocessing is needed
    if type(column_transformer) == sklearn.pipeline.Pipeline:
        l_transformers = [(name, trans, None, None) for step, name, trans in column_transformer._iter()]
    else:
        # For column transformers, follow the original method
        l_transformers = list(column_transformer._iter(fitted=True))
    
    
    for name, trans, column, _ in l_transformers: 
        if type(trans) == sklearn.pipeline.Pipeline:
            # Recursive call on pipeline
            _names = get_feature_names(trans)
            # if pipeline has no transformer that returns names
            if len(_names)==0:
                _names = [name + "__" + f for f in column]
            feature_names.extend(_names)
        else:
            feature_names.extend(get_names(trans))
    
    return feature_names

import sklearn
get_feature_names(col)

X_train.shape

categorical_transformer = OneHotEncoder(handle_unknown="ignore")
cat_data=pd.DataFrame(categorical_transformer.fit_transform(X[['Departments ']]).toarray())
X=X.join(cat_data)
X.drop('Departments ', axis=1, inplace=True)

X.isnull().sum()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y ,random_state=101)



X_train.isnull().sum()

gradient_model = GradientBoostingClassifier(n_estimators=1000, max_depth=5, learning_rate=0.2, random_state=101 )

clf = Pipeline(steps=[("classifier", gradient_model)])

clf.fit(X_train, y_train)

X_train.head()

cv = KFold(n_splits=10, shuffle=True, random_state=101)
scoring = ({'f1_left': make_scorer(f1_score, labels = ['left']),
             'precision_left' : make_scorer(precision_score, labels = ['left']),
            'recall_left': make_scorer(recall_score, labels = ['left'])})

scores = cross_validate(clf, X_train, y_train, scoring=scoring, cv=cv)
df_scores = pd.DataFrame(scores, index = range(1, 11))
df_scores.mean()[2:]

eval_metric(clf, X_train, y_train, X_test, y_test)